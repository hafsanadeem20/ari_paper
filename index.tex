% !TeX root = RJwrapper.tex
\title{The Automated R Instructor}
\author{by Sean Kross, John Muschelli, Jeffrey T. Leek}

\maketitle

\abstract{%
We present the \texttt{ari} package for video generation with audio
overlaid. The goal of the package is to be able to generate reproducible
videos, likely with the goal of education. We present an example of
generating videos with RMarkdown slide decks with inline comments as the
spoken script.\\
}

% Any extra LaTeX you need in the preamble

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

Videos are a crucial way people learn. Creating videos of an speaker
with slides take time, energy, and usually a bit if video editing
skills. A large issue with such videos is that updating the materials
either requires remaking the entire video or extensive editing and
splicing of new segments. We present \CRANpkg{ari}, the automated R
instructor to mitigate these issues by creating reproducible
presentations and videos that can be automatically generated. By using
\pkg{ari} we hope to be able to rapidly create and update video content.

The premise of the \pkg{ari} package is that you have visual content
(e.g.~slides, figures) and you want to explain them with words (i.e.~a
script) in a video. Synthesizing the audio from the script is done by
\href{https://aws.amazon.com/polly/}{Amazon Polly}, which is a text to
speech voice generation engine with over 21 languages, including a total
of 29 dialects, implemented in the \CRANpkg{aws.polly} package (Leeper,
2017). In addition to multiple languages, Amazon Polly provides voices
of different genders within the same language. Amazon Polly API has a
1500 character limit when synthesizing audio; \pkg{ari} splices scripts
into sufficiently-small chunks and creates the audio. The \pkg{ari}
package relies on the \CRANpkg{tuneR} package for reading and
manipulating audio output to combine split audio files and to add pauses
to audio files between slides (Ligges, Krey, Mersmann, and
Schnackenberg, 2018).

Once the audio is generated, it much be spliced with the images.
Multiple open source tools for video editing and splicing exist. The
\texttt{ffmpeg} (\url{http://www.ffmpeg.org/}) software is highly
powerful, has been thoroughly tested, and has been developed for almost
20 years; \pkg{ari} uses \texttt{ffmpeg} to overlay the images over the
audio. We have tested the videos on YouTube and the Coursera platform
viewers. A default specification is used in \pkg{ari}, such as bitrate,
audio and video codecs used, and output video format. Additional video
specifications can be applied to command-line arguments \texttt{ffmpeg}
through \pkg{ari}.

With these tools together, we can generate educational videos. The
scripts for these videos can be stored in plain text, and therefore be
version controlled. If the figures are created in a reproducible
framework, such as generated using R code, the entire video can be
reproducibly created and automatically updated.

\hypertarget{amazon-authentication}{%
\subsection{Amazon authentication}\label{amazon-authentication}}

In order to use Amazon Polly, one must set up R to use Amazon Web
Services, which uses \CRANpkg{aws.signature} for authentication (Leeper,
2018). In addition to \pkg{aws.signature} documentation, we have
provided as a tutorial
\href{http://seankross.com/2017/05/02/Access-Amazon-Web-Services-in-R.html}{here}.
In order to test the authentication required for \pkg{ari}, you can run
\texttt{aws.polly::list\_voices()}. The \texttt{aws.polly::synthesize}
function powers the backend authentication. NB: Amazon Polly is a paid
service, but has a free tier for the first year
(\url{https://aws.amazon.com/polly/pricing/}).

\hypertarget{making-videos-with-ari}{%
\subsection{\texorpdfstring{Making videos with
\texttt{ari}}{Making videos with ari}}\label{making-videos-with-ari}}

Videos can be produced form \texttt{ari} using a simple set of images
and a script, a Google Slide deck with the script in the notes section,
or an HTML slide presentation based in RMarkdown, where the script is in
the HTML comments.

The main workhorse of \pkg{ari} is the \texttt{ari\_stitch} function.
This function takes in a vector of images and a series of Wav audio
objects or audio filenames. Though most times a user has the text script
and needs to generate the audio narration, this function is useful if
the text to speech generation is done using another service, such as
Google in the \CRANpkg{googleLanguageR} package or Microsoft in the
\CRANpkg{mscstts} package (Edmondson, 2019; Muschelli, 2019).

\begin{Schunk}
\begin{Sinput}
library(tuneR)
library(ari)
result = ari_stitch(
  ari_example(c("mab1.png", "mab2.png")),
  list(noise(), noise()))
\end{Sinput}
\end{Schunk}

When the user has a text scrip, the higher-level \texttt{ari\_spin}
functioni is commonly used, which takes in a character vector of images
and a character vector of text (\texttt{paragraphs} argument). This text
is the ``script'' that is spoken over the images to create the output
video. The number of elements in the text need to be equal to the number
of images. The output video format is MP4 by default, but can be any
format (aka ``muxers'') that the \texttt{ffmpeg} installation support.
Supported codecs can be founded using the functions
\texttt{ffmpeg\_audio\_codecs} and \texttt{ffmpeg\_video\_codecs}.

The HTML slides are rendered using \CRANpkg{webshot}.

Some html slides take a bit to render on webshot, and can be dark gray
instead of white. If you change the \texttt{delay} argument in
\texttt{ari\_narrate}, passed to \texttt{webshot}, this can resolve some
issues, but may take a bit longer to run. Also, using
\texttt{capture\_method\ =\ "vectorized"} is faster, but may have some
issues, so run with \texttt{capture\_method\ =\ "iterative"} if this is
the case as so:

\hypertarget{accessibility}{%
\subsection{Accessibility}\label{accessibility}}

With respect to accessibility, as \pkg{ari} has the direct script that
was spoken, this provides for direct subtitles for those hard of hearing
rather than relying on other services, such as YouTube, to provide a
speech to text translation. Though some changes to the script are
required for AMazon Polly to correctly pronounce the information, these
can be changed using regular expressions in the script, and then passed
to \texttt{ari\_subtitles}.

\hypertarget{technical-stuff}{%
\subsection{Technical stuff}\label{technical-stuff}}

The \pkg{ari} package relies on \href{https://ffmpeg.org/}{FFmpeg}
(\textgreater{}= 3.2.4) to interleave the images and the audio files.

\hypertarget{future-directions}{%
\subsection{Future directions}\label{future-directions}}

We believe the heavy reliance on an \texttt{ffmpeg} installation can be
mitigated in the future with advances in the \pkg{av} package. Though
the \pkg{av} package has powerful functionality and is currently porting
more from \texttt{libav} and therefore \texttt{ffmpeg}, it currently
does not have the capabilities requried for \pkg{ari}. Although third
party installation from \url{https://ffmpeg.org/} can be burdensome to a
user, package managers such as \texttt{brew} for OSX and \texttt{choco}
for Windows provide installations.

Although we rely on Amazon Polly for voice synthesis, other packages
provide voice synthesis, such as \CRANpkg{mscstts} for Microsoft and
\CRANpkg{googleLanguageR} for Google. We aim to harmonize these
synthesis options, so that users can choose to create videos with the
services that they support or have access to.

Scripts can be automatically translated into other languages with
services like the \href{https://cloud.google.com/translate/docs/}{Google
Translation API}, which \pkg{googleLanguageR} provides an interface.
Amazon Polly can speak languages other than English. This means you can
write a lecture once and generate slides and videos in multiple
languages.

We have created a Docker environment
(\url{https://github.com/seankross/bologna}) with the requirements to
create videos using \pkg{ari}. This Docker image increases the level of
reproducibility and can be used to create standalone disk images to
create content.

\hypertarget{examples-from-readme---edit}{%
\subsection{Examples (FROM README -
edit)}\label{examples-from-readme---edit}}

These examples make use of the \texttt{ari\_example()} function. In
order to view the files mentioned here you should use
\texttt{file.show(ari\_example("{[}file\ name{]}"))}. You can watch an
example of a video produced by Ari
\href{https://youtu.be/dcIUu4GCOKU}{here}.

\begin{verbatim}
library(ari)

# First set up your AWS keys
Sys.setenv("AWS_ACCESS_KEY_ID" = "EA6TDV7ASDE9TL2WI6RJ",
           "AWS_SECRET_ACCESS_KEY" = "OSnwITbMzcAwvHfYDEmk10khb3g82j04Wj8Va4AA",
           "AWS_DEFAULT_REGION" = "us-east-2")

# Create a video from a Markdown file and slides
ari_narrate(
  ari_example("ari_intro_script.md"),
  ari_example("ari_intro.html"),
  voice = "Joey")

# Create a video from an R Markdown file with comments and slides
ari_narrate(
  ari_example("ari_comments.Rmd"),
  ari_example("ari_intro.html"),
  voice = "Kendra")

# Create a video from images and strings
ari_spin(
  ari_example(c("mab1.png", "mab2.png")),
  c("This is a graph.", "This is another graph"),
  voice = "Joanna")
\end{verbatim}

\hypertarget{rmarkdownhtml-slide-problems}{%
\subsubsection{RMarkdown/HTML slide
Problems}\label{rmarkdownhtml-slide-problems}}

\begin{verbatim}
ari_narrate(
  ari_example("ari_comments.Rmd"),
  ari_example("ari_intro.html"),
  voice = "Kendra",
  delay = 0.5,
  capture_method = "iterative")
\end{verbatim}

\bibliography{RJreferences}

\bibliography{RJreferences.bib}

\address{%
Sean Kross\\
Cognitive Science, University of California, San Diego\\
9500 Gilman Dr.\\ La Jolla, CA 92093\\
}
\href{mailto:author1@work}{\nolinkurl{author1@work}}

\address{%
John Muschelli\\
Department of Biostatistics, Johns Hopkins Bloomberg School of Public
Health\\
615 N Wolfe Street\\ Baltimore, MD 21231\\
}
\href{mailto:jmusche1@jhu.edu}{\nolinkurl{jmusche1@jhu.edu}}

\address{%
Jeffrey T. Leek\\
Department of Biostatistics, Johns Hopkins Bloomberg School of Public
Health\\
615 N Wolfe Street\\ Baltimore, MD 21231\\
}
\href{mailto:jtleek@jhu.edu}{\nolinkurl{jtleek@jhu.edu}}

